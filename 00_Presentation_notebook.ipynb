{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background:#83739E; color:white; font-size: 2.1em; text-align:center\"> \n",
    "    <br><b>Risk Evaluation for Retail Banks</b><br>\n",
    "    <br>Presentation Notebook<br><br> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right;\">Module 4: Machine Learning<br>\n",
    "Sprint 4: Machine Learning Capstone Project<br>\n",
    "Author : Renato Mariano</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from utils import utils\n",
    "from utils import EDA\n",
    "from feature_models import feat_eng\n",
    "from feature_models import pipelines\n",
    "from feature_models import model_select\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Introduction </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Capstone Project of of the Machine Learning Module! In this sprint, we embark on an exciting journey to develop a **risk evaluation service for retail banks**, leveraging the power of data science and machine learning.\n",
    "\n",
    "You and your friend are launching a startup focused on providing risk evaluation as a service for retail banks. This proof-of-concept (POC) plan outlines the steps you will take to investigate, analyze, and build a solution using machine learning. The dataset for analysis is obtained from Home Credit Group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following entity diagram shows the encompassed dataframes. They will be explored in more details during in the next sections of this notebook.\n",
    "\n",
    "<img src=\"images/00_entity-relationship_diagram.PNG\" width=850>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Exploratory Data Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyze the necessity of this model, we first need to evaluate **what proportion of money is given to defaulters**. Let's start with de distribution of this defaulters and then jump into the credit amounts given to them.\n",
    "\n",
    "Our defaulters are expressed as our **TARGET column**. As explained in the metadata, **this features shows if a client has presented difficulties to pay their loans** or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/01_defaulters_proportion.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our target (Loan Defaulters) variable is very **unevenly distributed** - about 92% of the client have payed their loans without any delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/02_credit-amount.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In examining the dataset, it becomes evident that approximately **$184 billion was disbursed in credit**. Notably, **around $13 billion, equivalent to approximately 7.5% of the total credit extended, was allocated to clients who eventually defaulted**. This observation underscores the **necessity for an automated system** capable of identifying defaulters accurately. Traditional methods employed by the bank seem insufficient to capture these nuances effectively, emphasizing the need for more sophisticated approaches in credit risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the exploration phase, numerous insights were found, prompting the creation of new features for our models. The initial features exhibited **limited correlation with the target variable**, various correlation methods were tailored to different feature types. Additionally, we conducted an analysis of numerical feature **skewness** and diligently searched for **anomalies** within the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this phase, we implemented several alterations to the dataset, including the creation of new features and the removal of anomalies. The impact of these changes on our predictive capabilities was assessed using a **LightGBM model**. To address the class imbalance inherent in our target variable, we have applied **weights to balance the classes**, adjusting primarily the **max_depth** parameter during experimentation.\n",
    "\n",
    "Given the imbalanced nature of our classes, we choose to evaluate our model's performance using the **ROC AUC metric**. ROC AUC (Receiver Operating Characteristic Area Under the Curve) is particularly well-suited for imbalanced classification tasks. It provides a robust measure of a model's ability to distinguish between positive and negative instances, offering a **balanced assessment even when classes are disproportionate**. This allow us to gauge the model's discriminative power across different threshold settings, crucial in scenarios where correctly identifying positive instances (defaulters) is of vital importance.\"\n",
    "\n",
    "We aimed at having a model with a ROC AUC of at least 0.80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cells will present a bit of the workflow adopted in this stage of the project. All of the transformers applied to the dataframe can be seen in the folder feature_models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is: (153755, 122)\n",
      "load_df took 2.378 seconds\n",
      "\n",
      "The shape of the data is: (61502, 122)\n",
      "load_df took 1.086 seconds\n",
      "\n",
      "The shape of the data is: (92254, 122)\n",
      "load_df took 2.257 seconds\n",
      "\n",
      "The shape of the data is: (1670214, 37)\n",
      "load_df took 10.915 seconds\n",
      "\n",
      "The shape of the data is: (13605401, 8)\n",
      "load_df took 25.102 seconds\n",
      "\n",
      "The shape of the data is: (1716428, 17)\n",
      "load_df took 4.672 seconds\n",
      "\n",
      "The shape of the data is: (32, 1)\n",
      "load_df took 0.015 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = utils.load_df(file_path=\"data/df_train.csv\")\n",
    "df_valid = utils.load_df(file_path=\"data/df_validation.csv\")\n",
    "df_test = utils.load_df(file_path=\"data/df_test.csv\")\n",
    "\n",
    "df_previous = utils.load_df(file_path=\"data/home-credit-default-risk/previous_application.csv\")\n",
    "df_installments = utils.load_df(file_path=\"data/home-credit-default-risk/installments_payments.csv\")\n",
    "df_bureau = utils.load_df(file_path=\"data/home-credit-default-risk/bureau.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the ideas behind the feature engineering process:\n",
    "\n",
    "For the **previous application** we computed, for each client:\n",
    "- the quantity of previous applications,\n",
    "- the quantity of rejected/accepted/cancelled/unused_offer applications,\n",
    "- aggregates for the continuous features for each client into \"mean\", \"median\", \"max\", \"min\".\n",
    "\n",
    "In the **Installments dataframe**, we generated:\n",
    "- the ratio of paid value by installment value (aggregates),\n",
    "- flag if client ever paid less,\n",
    "- delayed days of a payment (aggregates),\n",
    "- flag if a client has delayed a payment.\n",
    "- delayed days of a payment in the first year of application (365 days)\n",
    "\n",
    "For the **bureau data** we will compute, for each client:\n",
    "- aggregates for the continuous features for each client into \"mean\", \"median\", \"max\", \"min\".\n",
    "- application counts,\n",
    "- creating a credit active pivot table,\n",
    "- financial ratios (median, max, and min values for each SK_ID_CURR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_transf = feat_eng.PreviousApplicationTransformer().fit_transform(df_previous)\n",
    "df_installments_transf = feat_eng.InstallmentsTransformer().fit_transform(df_installments)\n",
    "df_bureau_transf = feat_eng.BureauTransformer().fit_transform(df_bureau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessing and feature engineering pipelines were applied in the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_drop_features(\n",
    "    df, df_previous_transf, df_installments_transf, df_bureau_transf, feats_to_keep\n",
    "):\n",
    "    df_transformed = df.merge(df_previous_transf, on=\"SK_ID_CURR\", how=\"left\").merge(\n",
    "        df_installments_transf, on=\"SK_ID_CURR\", how=\"left\"\n",
    "    ).merge(\n",
    "        df_bureau_transf, on=\"SK_ID_CURR\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    X = df_transformed.drop([\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "    y = df_transformed[\"TARGET\"]\n",
    "\n",
    "    feat_eng_pipe2 = Pipeline(\n",
    "    steps=[\n",
    "        (\"drop_mode_avg\", feat_eng.DropModeAVG()),\n",
    "        ('zero_null_transformer', feat_eng.ZeroToNullTransformer(columns=\"YEARS_BEGINEXPLUATATION_MEDI\")),\n",
    "        ('multiply_by_neg1', feat_eng.MultiplyByNeg1(columns=[col for col in df.columns if col.startswith('DAYS_')])),\n",
    "        ('days_empl_anomaly', feat_eng.HandleDaysEmployedAnomaly()),\n",
    "        ('map_loan_titles', feat_eng.ApplyMapToOrganization(column=\"ORGANIZATION_TYPE\", similarity_threshold=70)),\n",
    "        ('ext_sources_transformer', feat_eng.ExternalSourcesTransformer()),\n",
    "        ('financial_ratio_transformer', feat_eng.FinancialRatioTransformer()),\n",
    "        ('age_employment_transformer', feat_eng.AgeAndEmploymentTransformer()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_FE = feat_eng_pipe2.fit_transform(X)\n",
    "    num_feats, cat_feats, binary_feats, highcard_feats = utils.extract_features(X_FE)\n",
    "\n",
    "    preprocess_pipe = pipelines.create_preprocess_pipeline(\n",
    "        num_feats, binary_feats, highcard_feats\n",
    "    )\n",
    "    X_ready = preprocess_pipe.fit_transform(X_FE)\n",
    "    X_ready = X_ready.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '_', x))\n",
    "    \n",
    "    return X_ready, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153755, 32) 153755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__AMT_CREDIT</th>\n",
       "      <th>num__AMT_ANNUITY</th>\n",
       "      <th>num__DAYS_BIRTH</th>\n",
       "      <th>num__DAYS_EMPLOYED</th>\n",
       "      <th>num__OWN_CAR_AGE</th>\n",
       "      <th>num__REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>num__EXT_SOURCE_1</th>\n",
       "      <th>num__EXT_SOURCE_2</th>\n",
       "      <th>num__EXT_SOURCE_3</th>\n",
       "      <th>num__PREV_name_contract_refused</th>\n",
       "      <th>...</th>\n",
       "      <th>num__BU_debt_credit_sum_ratio_max</th>\n",
       "      <th>num__EXT_SOURCES_prod</th>\n",
       "      <th>num__EXT_SOURCES_sum</th>\n",
       "      <th>num__EXT_SOURCES_mean</th>\n",
       "      <th>num__amt_credit_annuity_ratio</th>\n",
       "      <th>num__amt_goods_price_annuity_ratio</th>\n",
       "      <th>num__amt_goods_price_credit_ratio</th>\n",
       "      <th>num__amt_goods_price_children_ratio</th>\n",
       "      <th>num__days_employed_percent</th>\n",
       "      <th>cat__NAME_EDUCATION_TYPE_Higher_education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.618</td>\n",
       "      <td>-0.878</td>\n",
       "      <td>-0.969</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.233</td>\n",
       "      <td>-1.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>-1.353</td>\n",
       "      <td>-1.848</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.642</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.246</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>0.393</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.204</td>\n",
       "      <td>1.229</td>\n",
       "      <td>0.742</td>\n",
       "      <td>-0.671</td>\n",
       "      <td>0.269</td>\n",
       "      <td>-0.256</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.918</td>\n",
       "      <td>0.885</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>0.441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.758</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.554</td>\n",
       "      <td>1.391</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.542</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__AMT_CREDIT  num__AMT_ANNUITY  num__DAYS_BIRTH  num__DAYS_EMPLOYED  \\\n",
       "0           -0.618            -0.878           -0.969              -0.244   \n",
       "1            1.246             0.545            0.012              -0.179   \n",
       "2            1.918             0.885           -0.368               0.441   \n",
       "\n",
       "   num__OWN_CAR_AGE  num__REG_CITY_NOT_LIVE_CITY  num__EXT_SOURCE_1  \\\n",
       "0               NaN                        1.000             -1.233   \n",
       "1             0.300                        1.000              0.061   \n",
       "2               NaN                        0.000              0.027   \n",
       "\n",
       "   num__EXT_SOURCE_2  num__EXT_SOURCE_3  num__PREV_name_contract_refused  ...  \\\n",
       "0             -1.375                NaN                            0.500  ...   \n",
       "1              0.152                NaN                              NaN  ...   \n",
       "2              0.046              0.197                              NaN  ...   \n",
       "\n",
       "   num__BU_debt_credit_sum_ratio_max  num__EXT_SOURCES_prod  \\\n",
       "0                                NaN                 -0.754   \n",
       "1                             -0.796                  0.393   \n",
       "2                             -0.758                 -0.145   \n",
       "\n",
       "   num__EXT_SOURCES_sum  num__EXT_SOURCES_mean  num__amt_credit_annuity_ratio  \\\n",
       "0                -1.353                 -1.848                          0.000   \n",
       "1                -0.013                  0.204                          1.229   \n",
       "2                 0.856                  0.184                          1.554   \n",
       "\n",
       "   num__amt_goods_price_annuity_ratio  num__amt_goods_price_credit_ratio  \\\n",
       "0                               0.056                              0.642   \n",
       "1                               0.742                             -0.671   \n",
       "2                               1.391                             -0.125   \n",
       "\n",
       "   num__amt_goods_price_children_ratio  num__days_employed_percent  \\\n",
       "0                               -0.337                       0.023   \n",
       "1                                0.269                      -0.256   \n",
       "2                                0.721                       0.542   \n",
       "\n",
       "   cat__NAME_EDUCATION_TYPE_Higher_education  \n",
       "0                                      0.000  \n",
       "1                                      1.000  \n",
       "2                                      1.000  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train = preprocess_and_drop_features(\n",
    "    df=df_train,\n",
    "    df_previous_transf=df_previous_transf,\n",
    "    df_installments_transf=df_installments_transf,\n",
    "    df_bureau_transf=df_bureau_transf\n",
    ")\n",
    "print(X_train.shape, y_train.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our cross-validation for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search_LGBM(X, y, param_distributions={\"max_depth\": randint(2, 10)}):\n",
    "    lgbm_model = LGBMClassifier(random_state=1, class_weight='balanced', verbose=-1, learning_rate=0.01, n_estimators=10)\n",
    "    randomized_search = RandomizedSearchCV(lgbm_model, param_distributions=param_distributions, n_iter=10, cv=5, random_state=1, scoring='roc_auc')\n",
    "    \n",
    "    return randomized_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                            learning_rate=0.01, n_estimators=10,\n",
       "                                            random_state=1, verbose=-1),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002820186CF10&gt;},\n",
       "                   random_state=1, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                            learning_rate=0.01, n_estimators=10,\n",
       "                                            random_state=1, verbose=-1),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002820186CF10&gt;},\n",
       "                   random_state=1, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.01, n_estimators=10,\n",
       "               random_state=1, verbose=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, learning_rate=0.01, n_estimators=10,\n",
       "               random_state=1, verbose=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                            learning_rate=0.01, n_estimators=10,\n",
       "                                            random_state=1, verbose=-1),\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x000002820186CF10>},\n",
       "                   random_state=1, scoring='roc_auc')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomized_search4 = randomized_search_LGBM(X_train, y_train)\n",
    "randomized_search4 = randomized_search4.fit(X_train, y_train)\n",
    "randomized_search4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LGBMClassifier(class_weight='balanced', learning_rate=0.01, max_depth=9,\n",
       "                n_estimators=10, random_state=1, verbose=-1),\n",
       " 'best_params': {'max_depth': 9},\n",
       " 'best_score': 0.734603979468497}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbm_results4 = {\n",
    "    'model': randomized_search4.best_estimator_,\n",
    "    'best_params': randomized_search4.best_params_,\n",
    "    'best_score': randomized_search4.best_score_\n",
    "}\n",
    "\n",
    "lgbm_results4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "best_lgbm_model4 = randomized_search4.best_estimator_\n",
    "model_select.plot_feature_importance(best_lgbm_model4, X_train, y_train, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/03_feature_importance.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our latest round of feature engineering, despite several promising additions to our model, the **results remained somewhat discouraging**, yielding a **ROC AUC of 0.7343**. Notably, many of the newly **engineered features** secured positions **in the Top 10** in terms of importance. However, this apparent success did not translate into a substantial improvement in performance. To provide context, **our initial run** focused solely on the main datatable, producing a baseline **ROC AUC of 0.7186**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Feature Selection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our data has currently 324 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our data has currently {X_train.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataframe had at this stage many features, this increases the chances that our models will be focusing efforts on features that don't add much to our predictions and increases the dimensional space of our features (curse of dimensionality). Some of these features can be multicolinear as well.\n",
    "\n",
    "The **following steps** were performed to reduce the amount of features:\n",
    "- Remove features with more than 75% Null Values.\n",
    "- Check and remove colinear features, but only if they were not deemed important contributors to the model's performance.\n",
    "- Drop irrelevant features for the LGBM model.\n",
    "\n",
    "As a result, only 37 features were maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we ran 4 models: **Decision Tree, XGBoost, LightGBM and CatBoost**. They were input in a cross-validation setup with 5 folds and randomized search for hyperparameters tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "class_weight = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "param_distributions = {\n",
    "    'DecisionTree': {\n",
    "        'model__max_depth': randint(3, 10),\n",
    "        'model__min_samples_leaf': randint(30, 101)\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': randint(10, 51),\n",
    "        'model__learning_rate': uniform(0.01, 0.05),\n",
    "        'model__max_depth': randint(3, 10)\n",
    "    },\n",
    "    'LGBM': {\n",
    "        'model__n_estimators': randint(10, 51),\n",
    "        'model__learning_rate': uniform(0.01, 0.05),\n",
    "        'model__max_depth': randint(3, 10),\n",
    "        'model__class_weight': [None, class_weight]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model__iterations': randint(10, 51),\n",
    "        'model__learning_rate': uniform(0.01, 0.05),\n",
    "        'model__depth': randint(3, 10),\n",
    "        'model__class_weights': [None, class_weight]\n",
    "    },\n",
    "}\n",
    "\n",
    "models = [\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=1, class_weight='balanced')),\n",
    "    ('XGBoost', XGBClassifier(random_state=1, class_weight=class_weight)), \n",
    "    ('LGBM', LGBMClassifier(random_state=1, class_weight='balanced', verbose=-1)),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=1, class_weights=class_weight, verbose=False)),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "feat_importance_result = {}\n",
    "\n",
    "for model_name, model in models:\n",
    "    model_pipeline = Pipeline([\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    param_dist = param_distributions.get(model_name, {})\n",
    "    randomized_search = RandomizedSearchCV(model_pipeline, param_distributions=param_dist, n_iter=10, cv=5, scoring=\"roc_auc\", random_state=1)\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "        \n",
    "    results[model_name] = {\n",
    "        'model': randomized_search.best_estimator_,\n",
    "        'best_params': randomized_search.best_params_,\n",
    "        'best_score': randomized_search.best_score_,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models presented similar results in terms of ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/04_roc-curve.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the confusion matrices bellow, we see however that the **XGBoost** did not perform well for the chosen threshold because it **mostly predicted values for the majority class** (0-Non-defaulters).\n",
    "\n",
    "All of the **other models** seem to present **very similar results** of precision and recall for both classes, with the **Decision Tree performing a little better** in predicting correctly the class **1-Defauters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/05_confusion-matrices.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We jump now into a analysis of the **Precision-Recall curve** to try to find an optimal threshold for our results (but still with focus on Recall for the defaulters class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/06_threshold_analysis.png\" width=950>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that finding the **optimal F1-Score comes with an obvious loss in Recall** for most of the models. This value drop from about 66% to 45%. In the context where we would like to predict defaulters, this change in threshold would not represent an advantage.\n",
    "\n",
    "Something to notice here is that the curves of the XGBoost and CatBoost are higher than the other models, which depicts a slightly better precision-recall curve.\n",
    "\n",
    "In the case of the **XGBoost**, the situation is completely different, with the standard threshold of 0.5 the levels of recall for our class of interest was 0. In this case, we applied a funciton to return a threshold for a given recall value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were further evaluated in terms of feature importance and using the SHAP library. **Insights about the most relevant features can be seen in the conclusion**.\n",
    "\n",
    "The models were lastly checked on the test data. Here, we checked still for all the boosting models, since the goal of the work was to deploy some machine learning models (not only one). The results were very similar to what was obtained using the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Deployment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deployment of our machine learning models was made using FastAPI. A Docker image was created and deployed on the Google Cloud Platform.\n",
    "\n",
    "We ran into a problem with one of the One-Hot-Encoded features at this stage and deployed the model on the processed features. The depolyed model can be accessed through the link: https://risk-retail-banks-nhk7sfh42a-oe.a.run.app/docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Feasability Analysis</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis was performed for our LightGBM model results. Only the test dataset was used, so one can expect a much lower sum of issued credit than in the initial analysis of the necessity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of given credit on the test data: $55,365,306,399.00\n"
     ]
    }
   ],
   "source": [
    "money_df = utils.load_df(file_path=\"data/money_df.csv\")\n",
    "print(f\"Sum of given credit on the test data: ${money_df['AMT_CREDIT'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/07_feasability.png\" width=650>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions highlight that our model is rejecting about 23.4% of applied credit by Non-defaulters, as we evaluate bellow, this value represents about 13 Billion dollars of non-issued credit. This is directly translated as money loss for our bank institution.\n",
    "\n",
    "With our model, we will correctly not issue 4.7% of default credits ($2.6 Bi), but still provide about 2.9% ($1.6 Bi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-defaulters\n",
      "Issued Credit Non-Defaulters: $38,217,772,917.00\n",
      "Value Lost by Rejecting Non-Defaulters: $12,956,082,079.50\n",
      "\n",
      "Defaulters\n",
      "Issued Credit True Defaulters: $1,586,499,286.50\n",
      "Value Gained by Rejecting True Defaulters: $2,604,952,116.00\n",
      "\n",
      "Total money gained or not lost: $40,822,725,033.00\n",
      "Total money lost: $14,542,581,366.00\n"
     ]
    }
   ],
   "source": [
    "value_lost_non_defaulters = money_df.loc[(money_df['y'] == 0) & (money_df['y_hat'] == 1), 'AMT_CREDIT'].sum()\n",
    "value_gained_non_defaulters = money_df.loc[(money_df['y'] == 0) & (money_df['y_hat'] == 0), 'AMT_CREDIT'].sum()\n",
    "\n",
    "value_lost_defaulters = money_df.loc[(money_df['y'] == 1) & (money_df['y_hat'] == 0), 'AMT_CREDIT'].sum()\n",
    "value_not_lost_defaulters = money_df.loc[(money_df['y'] == 1) & (money_df['y_hat'] == 1), 'AMT_CREDIT'].sum()\n",
    "\n",
    "print(\"Non-defaulters\")\n",
    "print(f\"Issued Credit Non-Defaulters: ${value_gained_non_defaulters:,.2f}\")\n",
    "print(f\"Value Lost by Rejecting Non-Defaulters: ${value_lost_non_defaulters:,.2f}\\n\")\n",
    "print(\"Defaulters\")\n",
    "print(f\"Issued Credit True Defaulters: ${value_lost_defaulters:,.2f}\")\n",
    "print(f\"Value Gained by Rejecting True Defaulters: ${value_not_lost_defaulters:,.2f}\\n\")\n",
    "print(f\"Total money gained or not lost: ${value_gained_non_defaulters + value_not_lost_defaulters:,.2f}\")\n",
    "print(f\"Total money lost: ${value_lost_non_defaulters + value_lost_defaulters:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite discouraging since we got low values of precision and recall.\n",
    "\n",
    "This model could still be applied, if there is always a credit expert who will evaluate rejected applications and decide if they should really be rejected or not. Many ways to improve the model results are discussed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#774CAD\">Conclusion</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our machine learning boosting models achieve results ROC AUC values around 0.76, having for the choosen/given threshold Recall slightly above 65%.\n",
    "\n",
    "After this evaluation, we know that our models are far from perfect and that there is a lot of room for improvement. Some conclusions on the most important features can be however made:\n",
    "- **External sources play a key role** in a way that if a client has bad sources they can be already denied a loan;\n",
    "- Another vital feature is the **ratio between the requested amount and the final credit amount** (in the previous application);\n",
    "- The **Higher Education** tends to push clients towards being good payers;\n",
    "- Another feature that seems to define good payers is **ratio between the Current debt and Current credit amount** (in the Credit Bureau);\n",
    "\n",
    "How to improve the model results:\n",
    "- Invest time on the inexplored dataframes;\n",
    "- Bring more aggregated features from the previous application/installments to the model;\n",
    "- Invest computational resources to generate features automatically (too much time invested on feature engineering);\n",
    "- Compute interest rates;\n",
    "- Create new aggregations for subsamples of the dataframes, i.e. NAME_PRODUCT_TYPE == \"Approved\"/\"Cancelled\", or CREDIT_ACTIVE == \"bad debt\"; \n",
    "- Try to impute values and check if there is increase in performance;\n",
    "\n",
    "General improvements:\n",
    "- To improve the workflow, some investiment can be done on the pipelines and creating mechanisms to integrate the data better;\n",
    "- Correlations can be transformed into a function and put in EDA.py.\n",
    "- Deployment of the initial features and passing through the pipelines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
